import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

# ==============================
# 1. Load Data
# ==============================

train = pd.read_csv("/content/train.csv")
test  = pd.read_csv("/content/test.csv")

# ==============================
# 2. Feature Engineering - TITLE
# ==============================

train['Title'] = train['Name'].str.extract(' ([A-Za-z]+)\.', expand=False)
test['Title']  = test['Name'].str.extract(' ([A-Za-z]+)\.', expand=False)

# Simplify rare titles
rare_titles = ['Lady','Countess','Capt','Col','Don','Dr','Major',
               'Rev','Sir','Jonkheer','Dona']

train['Title'] = train['Title'].replace(rare_titles, 'Rare')
test['Title']  = test['Title'].replace(rare_titles, 'Rare')

train['Title'] = train['Title'].replace(['Mlle','Ms'], 'Miss')
train['Title'] = train['Title'].replace(['Mme'], 'Mrs')

test['Title'] = test['Title'].replace(['Mlle','Ms'], 'Miss')
test['Title'] = test['Title'].replace(['Mme'], 'Mrs')

# ==============================
# 3. Drop Unnecessary Columns
# ==============================

train.drop(['Cabin','Ticket'], axis=1, inplace=True)
test.drop(['Cabin','Ticket'], axis=1, inplace=True)

# ==============================
# 4. Fill Missing Values
# ==============================

# Embarked
train['Embarked'].fillna(train['Embarked'].mode()[0], inplace=True)
test['Embarked'].fillna(test['Embarked'].mode()[0], inplace=True)

# Age using Pclass mean
age_mean = train.groupby('Pclass')['Age'].mean()

for i in age_mean.index:
    train.loc[(train['Pclass']==i) & (train['Age'].isnull()), 'Age'] = age_mean[i]
    test.loc[(test['Pclass']==i) & (test['Age'].isnull()), 'Age'] = age_mean[i]

# Fare
test['Fare'].fillna(train['Fare'].mean(), inplace=True)

# Log transform Fare (ONLY ONCE)
train['Fare'] = np.log1p(train['Fare'])
test['Fare']  = np.log1p(test['Fare'])

# ==============================
# 5. More Feature Engineering
# ==============================

# Family size
train['familysize'] = train['SibSp'] + train['Parch'] + 1
test['familysize']  = test['SibSp'] + test['Parch'] + 1

# Single
train['single'] = 1
test['single'] = 1

train.loc[(train['SibSp']>=1) | (train['Parch']>=1), 'single'] = 0
test.loc[(test['SibSp']>=1) | (test['Parch']>=1), 'single'] = 0

# Age groups
def age_group(age):
    if age < 12:
        return "child"
    elif age < 21:
        return "teenage"
    elif age < 42:
        return "young"
    elif age < 60:
        return "adult"
    else:
        return "oldage"

train['agegroup'] = train['Age'].apply(age_group)
test['agegroup']  = test['Age'].apply(age_group)

# Sex + Pclass
train['Sex_Pclass'] = train['Sex'] + "_" + train['Pclass'].astype(str)
test['Sex_Pclass']  = test['Sex'] + "_" + test['Pclass'].astype(str)

# ==============================
# 6. Drop Name & PassengerId
# ==============================

train.drop(['Name','PassengerId'], axis=1, inplace=True)
passenger_ids = test['PassengerId']
test.drop(['Name','PassengerId'], axis=1, inplace=True)

# ==============================
# 7. One Hot Encoding
# ==============================

from sklearn.preprocessing import OneHotEncoder

categorical_cols = ['Sex','Embarked','agegroup','Sex_Pclass','Title']

encoder = OneHotEncoder(drop='first', sparse_output=False)

encoded_train = encoder.fit_transform(train[categorical_cols])
encoded_test  = encoder.transform(test[categorical_cols])

encoded_train_df = pd.DataFrame(
    encoded_train,
    columns=encoder.get_feature_names_out(categorical_cols),
    index=train.index
)

encoded_test_df = pd.DataFrame(
    encoded_test,
    columns=encoder.get_feature_names_out(categorical_cols),
    index=test.index
)

train = pd.concat([train.drop(categorical_cols, axis=1), encoded_train_df], axis=1)
test  = pd.concat([test.drop(categorical_cols, axis=1), encoded_test_df], axis=1)

# ==============================
# 8. Train Validation Split (FIXED)
# ==============================

X = train.drop('Survived', axis=1)
y = train['Survived']

from sklearn.model_selection import train_test_split
X_train, X_val, y_train, y_val = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# ==============================
# 9. Scaling
# ==============================

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()

X_train_scaled = scaler.fit_transform(X_train)
X_val_scaled   = scaler.transform(X_val)
X_test_scaled  = scaler.transform(test)

# ==============================
# 10. Models
# ==============================

from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier

model1 = LogisticRegression(max_iter=1000)

model2 = RandomForestClassifier(
    n_estimators=300,
    max_depth=5,
    random_state=42
)

model1.fit(X_train_scaled, y_train)
model2.fit(X_train_scaled, y_train)

# ==============================
# 11. Validation Evaluation
# ==============================

from sklearn.metrics import classification_report, accuracy_score

val_pred1 = model1.predict(X_val_scaled)
val_pred2 = model2.predict(X_val_scaled)

print("Logistic Regression\n")
print(classification_report(y_val, val_pred1))
print("Accuracy:", accuracy_score(y_val, val_pred1))

print("\nRandom Forest\n")
print(classification_report(y_val, val_pred2))
print("Accuracy:", accuracy_score(y_val, val_pred2))

# ==============================
# 12. Final Test Prediction
# ==============================

final_pred = model2.predict(X_test_scaled)

submission = pd.DataFrame({
    "PassengerId": passenger_ids,
    "Survived": final_pred
})

submission.to_csv("final_submission.csv", index=False)

print("\nSubmission file created successfully!")
